{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install isodate\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import isodate\n",
    "from dateutil import parser\n",
    "import datetime as dt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'AIzaSyBoO6MSKPQ9baLdYL_CXnfHygBy_jf0nTg'\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "\n",
    "\n",
    "#a list of data channels\n",
    "data_coding_channel = {\n",
    "# DS/DA\n",
    "'Tina_Huang' : 'UC2UXDak6o7rBm23k3Vv5dww',\n",
    "'Luke Barousse' : 'UCLLw7jmFsvfIVaUFsLs8mlQ',\n",
    "'Thu Vu data analytics' : 'UCJQJAI7IjbLcpsjWdSzYz0Q',\n",
    "'Alex The Analyst' : 'UC7cs8q-gJRlGwj4A8OmCmXg',\n",
    "'Data Interview Pro' : 'UCAWsBMQY4KSuOuGODki-l7A',\n",
    "# DE\n",
    "'Andreas Kretz' : 'UCY8mzqqGwl5_bTpBY9qLMAA',\n",
    "'Data with Zach' : 'UCAq9f7jFEA7Mtl3qOZy2h1A',\n",
    "'Karolina Sowinska' : 'UCAxnMry1lETl47xQWABvH7g',\n",
    "'E-Learning Bridge' : 'UCBGcs9XTL5U34oaSn_AsHqw',\n",
    "'Seattle Data Guy' : 'UCmLGJ3VYBcfRaWbP6JLJcpA'}\n",
    "\n",
    "youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, developerKey=api_key )\n",
    "\n",
    "# print(json.dumps(response,indent=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_info(youtube):\n",
    "    request = youtube.channels().list(\n",
    "    part=\"snippet,contentDetails,statistics\",\n",
    "    id=','.join(data_coding_channel[channel] for channel in data_coding_channel))\n",
    "    response = request.execute()\n",
    "\n",
    "    channel_data = []\n",
    "    for channel in response['items']:\n",
    "        channel_id = channel['id']\n",
    "        channel_title = channel['snippet']['title']\n",
    "        channel_description = channel['snippet']['description']\n",
    "        channel_publish_at = channel['snippet']['publishedAt']\n",
    "        channel_country = channel['snippet']['country']\n",
    "        channel_view_count = channel['statistics']['viewCount']\n",
    "        channel_subscriber_count = channel['statistics']['subscriberCount']\n",
    "        channel_video_count = channel['statistics']['videoCount']\n",
    "        channel_playlist_id = channel['contentDetails']['relatedPlaylists']['uploads']\n",
    "        channel_element = {\n",
    "            \"channel_id\" : channel_id,\n",
    "            \"channel_title\" : channel_title,\n",
    "            \"channel_publish_at\" : channel_publish_at,\n",
    "            \"channel_description\" : channel_description,\n",
    "            \"channel_country\" : channel_country, \n",
    "            \"channel_view_count\" : channel_view_count,\n",
    "            \"channel_subscriber_count\" : channel_subscriber_count,\n",
    "            \"channel_video_count\" : channel_video_count,\n",
    "            'channel_playlist_id' :  channel_playlist_id }\n",
    "        channel_data.append(channel_element)\n",
    "    return pd.DataFrame(channel_data)\n",
    "\n",
    "# get_channel_info(youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_playlist_data(youtube):\n",
    "#     playlist_data = []\n",
    "#     playlist_ids = get_channel_info(youtube)['channel_playlist_id'].tolist()\n",
    "#     for playlist_id in playlist_ids:\n",
    "#         request = youtube.playlistItems().list(\n",
    "#         part=\"snippet,contentDetails\",\n",
    "#         maxResults = 50,\n",
    "#         playlistId= playlist_id)\n",
    "#         response = request.execute()\n",
    "        \n",
    "#         for playlist in response['items']:\n",
    "#             playlist_id = playlist[\"snippet\"]['playlistId']\n",
    "#             video_id = playlist['contentDetails'][\"videoId\"]\n",
    "#             playlist_data.append([playlist_id, video_id])\n",
    "    \n",
    "#     return pd.DataFrame(playlist_data,columns= ['playlist_id','video_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_info(youtube):\n",
    "    playlist_df = pd.DataFrame()\n",
    "    def get_individual_playlist_data(youtube, playlist_id):  \n",
    "        request = youtube.playlistItems().list(\n",
    "                            part=\"snippet,contentDetails\",\n",
    "                            maxResults = 50,\n",
    "                            playlistId= playlist_id)\n",
    "        response = request.execute()\n",
    "\n",
    "        all_playlist_id = []\n",
    "        all_video_id = []\n",
    "        for playlist in response['items']:\n",
    "            all_playlist_id.append(playlist[\"snippet\"]['playlistId'])\n",
    "            all_video_id.append(playlist['contentDetails'][\"videoId\"])\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        more_pages = True\n",
    "\n",
    "        while more_pages:\n",
    "            if next_page_token is None:\n",
    "                more_pages = False\n",
    "            else:\n",
    "                request = youtube.playlistItems().list(\n",
    "                        part='snippet,contentDetails',\n",
    "                        playlistId= playlist_id,\n",
    "                        maxResults = 50,\n",
    "                        pageToken = next_page_token)\n",
    "                response = request.execute()\n",
    "\n",
    "                for playlist in response['items']:\n",
    "                    all_playlist_id.append(playlist[\"snippet\"]['playlistId'])\n",
    "                    all_video_id.append(playlist['contentDetails'][\"videoId\"])\n",
    "            \n",
    "                next_page_token = response.get('nextPageToken')\n",
    "\n",
    "        return pd.DataFrame({\"playlist_id\" : all_playlist_id, \n",
    "                            \"video_id\" : all_video_id})\n",
    "\n",
    "    for playlist_id in get_channel_info(youtube)['channel_playlist_id'].tolist():\n",
    "        playlist_df = playlist_df.append(get_individual_playlist_data(youtube, playlist_id))\n",
    "    return playlist_df\n",
    "\n",
    "\n",
    "# get_playlist_info(youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_info(youtube):\n",
    "    all_video = []\n",
    "    video_ids = get_playlist_info(youtube)['video_id']\n",
    "    for video_id in video_ids:\n",
    "        request = youtube.videos().list(\n",
    "                part=\"snippet,contentDetails,statistics\",\n",
    "                id= video_id\n",
    "            )\n",
    "        response = request.execute()\n",
    "        for video in response['items']:\n",
    "            stats = {'snippet' : ['publishedAt','title','description','tags'],\n",
    "                    'statistics': ['viewCount','likeCount','favoriteCount','commentCount'],\n",
    "                    'contentDetails': ['duration','definition','caption']}\n",
    "            video_detail = {}\n",
    "            video_detail['video_id'] = video['id']\n",
    "\n",
    "            for stat in stats:\n",
    "                for detail in stats[stat]:\n",
    "                    try: \n",
    "                        video_detail[detail] = video[stat][detail]\n",
    "                    except:\n",
    "                        video_detail[detail] = None\n",
    "            all_video.append(video_detail)\n",
    "\n",
    "    return pd.DataFrame(all_video)\n",
    "\n",
    "\n",
    "# get_video_info(youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DS_DA = ['UC2UXDak6o7rBm23k3Vv5dww','UCLLw7jmFsvfIVaUFsLs8mlQ','UCJQJAI7IjbLcpsjWdSzYz0Q','UC7cs8q-gJRlGwj4A8OmCmXg','UCAWsBMQY4KSuOuGODki-l7A']\n",
    "# stop_words.extend(\"I'm\",'hello','')\n",
    "def channel_data_processing(channel, category_list = DS_DA):\n",
    "    numeric_cols = ['channel_view_count','channel_subscriber_count','channel_video_count']\n",
    "    channel[numeric_cols] = channel[numeric_cols].apply(pd.to_numeric, errors = 'coerce', axis = 1)\n",
    "    channel['channel_publish_at'] = channel['channel_publish_at'].apply(lambda x: parser.parse(x).date())\n",
    "    channel['channel_category'] = channel['channel_id'].apply(lambda x: 'DS_DA' if x in category_list else 'DE') \n",
    "    channel['insert_date'] = pd.to_datetime(\"today\").date()\n",
    "    return channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend([\"thank\",\"what's up\",\"time\",\"thing\",\"best\",\"ask\",\"about\",\"get\",\"vs\",\"vs.\",\"find\",\"help\",\"real\",\"work\",\"website\",\"also\",\"almost\",\"as\",\"any\",\"blow\",\"mind\",\"choice\",'content','effective','non','frequently','ever','learn','change','sunday','2020','2021',\"2022\",\"p0\",\"p1\",\"p2\",\"p3\",\"p4\",\"air\",\"p5\",\"p6\",\"late\",\"truth\",\"solve\",\n",
    "\"full\",\"different\",\"world\",\"word\",\"next\",\"minute\",\"month\",\"year\",\"get\",\"go\",\"self\",\"story\",\"super\",\"really\",\"better\",\"measure\",\"what's,\",\"start\",\"over\",\"successfully\",'success','succeed','begin','start','good','fresh','course','tip','pro',\"3rd\",\"beautiful\",\"bad\",\"improve\",\"step\",\"must\",\"previous\",\"44\",\"34\",\"24\",\"solve\",\"instal\",\n",
    "\"people\",\"person\",\"according\",\"real\",\"great\",\"stay\",\"sane\",\"come\",\"point\",\"favorite\",\"idea\",\"choose\",\"halo\",\"make\",\"used\",\"week\",\"start\",\"write\",\"based\",\"base\",'connect','v','realize','realistic','beginner','intermediate','advance','advanced',\"near\",\"close\",\"funny\",\"w\",\"no info\",\"install\",\"everything\",\n",
    "\"land\",\"easily\",\"smoothly\",\"personal\",\"cant\",\"end\",\"like\",\"tell\",\"every\",\"everyone\",\"all\",\"most\",\"more\",\"easy\",\"simple\",\"guy\",\"crack\",\"role\",\"position\",'want','useful','new','important','watch','youtube','know','other','worth','part','from','wali','alex','wild','youll','yes','no','try','episode','top','way','yet','worker','from','without','do','to','single','page',\n",
    "'pages','update','updates','would','dont','donts','wins','winning','boy','boys','zhai','need','use','uses','using','knows','woudnt','live','first','short','shorts','parts','other','others','knew','show','shows','topic','topics','how','talk','needs','went',\"intuition\",\"disappointment\",\"massive\",\"32\",\"1799\",\"buy\",\"feel\",\n",
    "'zero','1','2','3','4','5','6','7','8','9','10','15','who','in','door','area','veronica','worse','worst','wish','wannable','wohhoo','worksdont','hero','single','free','whats','level','freshers','monthly','bi-weekly','yealy',\"level\",\"hard\",\"easy\",\"swing\",\"sub\",\"back\",\"despite\",\n",
    "'difference','hour','per','stop','lazy','like','hate','dislike','love','still','one','five','ten','two','unique','temp','try','summer','winter','type','unique','rural','face','matter','york','value','void','avoid','who','big','small','become','create',\n",
    "'strong','type','understand','understood','weekly','take','took','suck','tell','talk','ultimate','wrong','year','avoid','upload','stand','upcoming','unblock','underrate','successful','gonna','build','actual','actually','amazing','custom','proper','random','im','maximize','minimize','outcome','recommend','fry','burn','give','havent',\n",
    "\"complete\",\"reject\",\"50\",\"competitive\",\"right\",\"major\",\"reach\",\"20th\",\"21st\",\"pick\",\"much\",\"fast\",\"online\",\"consult\",\"modern\",\"last\",\"break\",\"reason\",\"reality\",\"replace\",\"win\",\"natural\",\"x\",\"west\",\"eliza\",\"load\",\"legendary\",\"video\",\"dirty\",\"chat\",\"issue\",\"final\",\"run\",\"luck\",\"follow\",\"lead\",\"32\",\"believe\",\"gritty\",\"ledengary\",\"cut\",\"west\",\"return\",\"massive\"])\n",
    "\n",
    "stop_words = set(stop_words)\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# text = 'apple apples be successes successful succeed successfully one day stopped stops stopping weekly weeks week data science simulate simulation simulates visualization visuals visual, visually!'\n",
    "\n",
    "def clean_video_title(title, stop_words = stop_words):\n",
    "\n",
    "    lemma_word = []\n",
    "    for w in title.lower().split():\n",
    "        word1 = wordnet_lemmatizer.lemmatize(w.strip(), pos = \"n\")\n",
    "        word2 = wordnet_lemmatizer.lemmatize(word1, pos = \"v\")\n",
    "        word3 = wordnet_lemmatizer.lemmatize(word2, pos = (\"a\"))\n",
    "        word4 = wordnet_lemmatizer.lemmatize(word3, pos = (\"r\"))\n",
    "        lemma_word.append(word4)\n",
    "        filtered_setence = [w for w in lemma_word if w not in stop_words]\n",
    "    return filtered_setence\n",
    "\n",
    "# clean_video_title(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1',\n",
       " '10',\n",
       " '15',\n",
       " '1799',\n",
       " '2',\n",
       " '2020',\n",
       " '2021',\n",
       " '2022',\n",
       " '20th',\n",
       " '21st',\n",
       " '24',\n",
       " '3',\n",
       " '32',\n",
       " '34',\n",
       " '3rd',\n",
       " '4',\n",
       " '44',\n",
       " '5',\n",
       " '50',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'according',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'air',\n",
       " 'alex',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'also',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'area',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'ask',\n",
       " 'at',\n",
       " 'avoid',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'base',\n",
       " 'based',\n",
       " 'be',\n",
       " 'beautiful',\n",
       " 'because',\n",
       " 'become',\n",
       " 'been',\n",
       " 'before',\n",
       " 'begin',\n",
       " 'beginner',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'bi-weekly',\n",
       " 'big',\n",
       " 'blow',\n",
       " 'both',\n",
       " 'boy',\n",
       " 'boys',\n",
       " 'break',\n",
       " 'build',\n",
       " 'burn',\n",
       " 'but',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'can',\n",
       " 'cant',\n",
       " 'change',\n",
       " 'chat',\n",
       " 'choice',\n",
       " 'choose',\n",
       " 'close',\n",
       " 'come',\n",
       " 'competitive',\n",
       " 'complete',\n",
       " 'connect',\n",
       " 'consult',\n",
       " 'content',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'course',\n",
       " 'crack',\n",
       " 'create',\n",
       " 'custom',\n",
       " 'cut',\n",
       " 'd',\n",
       " 'despite',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'difference',\n",
       " 'different',\n",
       " 'dirty',\n",
       " 'disappointment',\n",
       " 'dislike',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'dont',\n",
       " 'donts',\n",
       " 'door',\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'effective',\n",
       " 'eliza',\n",
       " 'end',\n",
       " 'episode',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'face',\n",
       " 'fast',\n",
       " 'favorite',\n",
       " 'feel',\n",
       " 'few',\n",
       " 'final',\n",
       " 'find',\n",
       " 'first',\n",
       " 'five',\n",
       " 'follow',\n",
       " 'for',\n",
       " 'free',\n",
       " 'frequently',\n",
       " 'fresh',\n",
       " 'freshers',\n",
       " 'from',\n",
       " 'fry',\n",
       " 'full',\n",
       " 'funny',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'gonna',\n",
       " 'good',\n",
       " 'great',\n",
       " 'gritty',\n",
       " 'guy',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'halo',\n",
       " 'hard',\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'hate',\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'havent',\n",
       " 'having',\n",
       " 'he',\n",
       " 'help',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hero',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hour',\n",
       " 'how',\n",
       " 'i',\n",
       " 'idea',\n",
       " 'if',\n",
       " 'im',\n",
       " 'important',\n",
       " 'improve',\n",
       " 'in',\n",
       " 'instal',\n",
       " 'install',\n",
       " 'intermediate',\n",
       " 'into',\n",
       " 'intuition',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'issue',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'knows',\n",
       " 'land',\n",
       " 'last',\n",
       " 'late',\n",
       " 'lazy',\n",
       " 'lead',\n",
       " 'learn',\n",
       " 'ledengary',\n",
       " 'legendary',\n",
       " 'level',\n",
       " 'like',\n",
       " 'live',\n",
       " 'll',\n",
       " 'load',\n",
       " 'love',\n",
       " 'luck',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'major',\n",
       " 'make',\n",
       " 'massive',\n",
       " 'matter',\n",
       " 'maximize',\n",
       " 'me',\n",
       " 'measure',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mind',\n",
       " 'minimize',\n",
       " 'minute',\n",
       " 'modern',\n",
       " 'month',\n",
       " 'monthly',\n",
       " 'more',\n",
       " 'most',\n",
       " 'much',\n",
       " 'must',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'natural',\n",
       " 'near',\n",
       " 'need',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'needs',\n",
       " 'new',\n",
       " 'next',\n",
       " 'no',\n",
       " 'no info',\n",
       " 'non',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'online',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outcome',\n",
       " 'over',\n",
       " 'own',\n",
       " 'p0',\n",
       " 'p1',\n",
       " 'p2',\n",
       " 'p3',\n",
       " 'p4',\n",
       " 'p5',\n",
       " 'p6',\n",
       " 'page',\n",
       " 'pages',\n",
       " 'part',\n",
       " 'parts',\n",
       " 'people',\n",
       " 'per',\n",
       " 'person',\n",
       " 'personal',\n",
       " 'pick',\n",
       " 'point',\n",
       " 'position',\n",
       " 'previous',\n",
       " 'pro',\n",
       " 'proper',\n",
       " 'random',\n",
       " 're',\n",
       " 'reach',\n",
       " 'real',\n",
       " 'realistic',\n",
       " 'reality',\n",
       " 'realize',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'recommend',\n",
       " 'reject',\n",
       " 'replace',\n",
       " 'return',\n",
       " 'right',\n",
       " 'role',\n",
       " 'run',\n",
       " 'rural',\n",
       " 's',\n",
       " 'same',\n",
       " 'sane',\n",
       " 'self',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'short',\n",
       " 'shorts',\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'show',\n",
       " 'shows',\n",
       " 'simple',\n",
       " 'single',\n",
       " 'small',\n",
       " 'smoothly',\n",
       " 'so',\n",
       " 'solve',\n",
       " 'some',\n",
       " 'stand',\n",
       " 'start',\n",
       " 'stay',\n",
       " 'step',\n",
       " 'still',\n",
       " 'stop',\n",
       " 'story',\n",
       " 'strong',\n",
       " 'sub',\n",
       " 'succeed',\n",
       " 'success',\n",
       " 'successful',\n",
       " 'successfully',\n",
       " 'such',\n",
       " 'suck',\n",
       " 'summer',\n",
       " 'sunday',\n",
       " 'super',\n",
       " 'swing',\n",
       " 't',\n",
       " 'take',\n",
       " 'talk',\n",
       " 'tell',\n",
       " 'temp',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'thing',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'time',\n",
       " 'tip',\n",
       " 'to',\n",
       " 'too',\n",
       " 'took',\n",
       " 'top',\n",
       " 'topic',\n",
       " 'topics',\n",
       " 'truth',\n",
       " 'try',\n",
       " 'two',\n",
       " 'type',\n",
       " 'ultimate',\n",
       " 'unblock',\n",
       " 'under',\n",
       " 'underrate',\n",
       " 'understand',\n",
       " 'understood',\n",
       " 'unique',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upcoming',\n",
       " 'update',\n",
       " 'updates',\n",
       " 'upload',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'v',\n",
       " 'value',\n",
       " 've',\n",
       " 'veronica',\n",
       " 'very',\n",
       " 'video',\n",
       " 'void',\n",
       " 'vs',\n",
       " 'vs.',\n",
       " 'w',\n",
       " 'wali',\n",
       " 'wannable',\n",
       " 'want',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'watch',\n",
       " 'way',\n",
       " 'we',\n",
       " 'website',\n",
       " 'week',\n",
       " 'weekly',\n",
       " 'went',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'west',\n",
       " 'what',\n",
       " \"what's up\",\n",
       " \"what's,\",\n",
       " 'whats',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'wild',\n",
       " 'will',\n",
       " 'win',\n",
       " 'winning',\n",
       " 'wins',\n",
       " 'winter',\n",
       " 'wish',\n",
       " 'with',\n",
       " 'without',\n",
       " 'wohhoo',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'word',\n",
       " 'work',\n",
       " 'worker',\n",
       " 'worksdont',\n",
       " 'world',\n",
       " 'worse',\n",
       " 'worst',\n",
       " 'worth',\n",
       " 'woudnt',\n",
       " 'would',\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'write',\n",
       " 'wrong',\n",
       " 'x',\n",
       " 'y',\n",
       " 'yealy',\n",
       " 'year',\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'york',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'youll',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'youtube',\n",
       " 'zero',\n",
       " 'zhai'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"stop\" in stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_data_processing(video, stop_words = stop_words):\n",
    "    numeric_cols = ['viewCount','likeCount','favoriteCount','commentCount']\n",
    "    video[numeric_cols] = video[numeric_cols].apply(pd.to_numeric, errors = 'coerce', axis = 1)\n",
    "    video['tags_count'] = video['tags'].apply(lambda x : 0 if x is None else len(x))\n",
    "    video['publishedAt'] = video['publishedAt'].apply(lambda x: parser.parse(x)) \n",
    "    video['publishDay'] = video['publishedAt'].apply(lambda x: x.strftime(\"%a\")) \n",
    "    video['durationinSecs'] = video['duration'].apply(lambda x: isodate.parse_duration(x))\n",
    "    video['durationinSecs'] = video['durationinSecs'].astype('timedelta64[s]')\n",
    "    video['insert_date'] = pd.to_datetime(\"today\").date()\n",
    "    video['title_2'] = video['title'].apply(lambda x : re.sub(r'[^\\w\\s]','', x))\n",
    "    video['title_word'] = video['title_2'].apply(lambda x : clean_video_title(x, stop_words=stop_words) )\n",
    "    video = video.drop(columns =['duration'], axis = 1 )\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playlist_data_processing(playlist):\n",
    "    playlist['insert_date'] = pd.to_datetime(\"today\").date()\n",
    "    return playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>insert_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UUAWsBMQY4KSuOuGODki-l7A</td>\n",
       "      <td>9TD-AYKnw7E</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UUAWsBMQY4KSuOuGODki-l7A</td>\n",
       "      <td>7fI3eA8VHbk</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UUAWsBMQY4KSuOuGODki-l7A</td>\n",
       "      <td>W_NBnkLLh7M</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UUAWsBMQY4KSuOuGODki-l7A</td>\n",
       "      <td>e-EL-6Vnkbg</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UUAWsBMQY4KSuOuGODki-l7A</td>\n",
       "      <td>1tfGvvVOF6Q</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>UUY8mzqqGwl5_bTpBY9qLMAA</td>\n",
       "      <td>RboQBZvZCh0</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>UUY8mzqqGwl5_bTpBY9qLMAA</td>\n",
       "      <td>7F9tBwTUSeY</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>UUY8mzqqGwl5_bTpBY9qLMAA</td>\n",
       "      <td>fib6izcFxv0</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>UUY8mzqqGwl5_bTpBY9qLMAA</td>\n",
       "      <td>riTtDkhQr_A</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>UUY8mzqqGwl5_bTpBY9qLMAA</td>\n",
       "      <td>LYtTBoL_lK8</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>977 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  playlist_id     video_id insert_date\n",
       "0    UUAWsBMQY4KSuOuGODki-l7A  9TD-AYKnw7E  2022-05-03\n",
       "1    UUAWsBMQY4KSuOuGODki-l7A  7fI3eA8VHbk  2022-05-03\n",
       "2    UUAWsBMQY4KSuOuGODki-l7A  W_NBnkLLh7M  2022-05-03\n",
       "3    UUAWsBMQY4KSuOuGODki-l7A  e-EL-6Vnkbg  2022-05-03\n",
       "4    UUAWsBMQY4KSuOuGODki-l7A  1tfGvvVOF6Q  2022-05-03\n",
       "..                        ...          ...         ...\n",
       "180  UUY8mzqqGwl5_bTpBY9qLMAA  RboQBZvZCh0  2022-05-03\n",
       "181  UUY8mzqqGwl5_bTpBY9qLMAA  7F9tBwTUSeY  2022-05-03\n",
       "182  UUY8mzqqGwl5_bTpBY9qLMAA  fib6izcFxv0  2022-05-03\n",
       "183  UUY8mzqqGwl5_bTpBY9qLMAA  riTtDkhQr_A  2022-05-03\n",
       "184  UUY8mzqqGwl5_bTpBY9qLMAA  LYtTBoL_lK8  2022-05-03\n",
       "\n",
       "[977 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Processing\n",
    "playlist = playlist_data_processing(get_playlist_info(youtube))\n",
    "playlist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>channel_publish_at</th>\n",
       "      <th>channel_description</th>\n",
       "      <th>channel_country</th>\n",
       "      <th>channel_view_count</th>\n",
       "      <th>channel_subscriber_count</th>\n",
       "      <th>channel_video_count</th>\n",
       "      <th>channel_playlist_id</th>\n",
       "      <th>channel_category</th>\n",
       "      <th>insert_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCY8mzqqGwl5_bTpBY9qLMAA</td>\n",
       "      <td>Andreas Kretz</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>I help you get into data engineering, the plum...</td>\n",
       "      <td>DE</td>\n",
       "      <td>746257</td>\n",
       "      <td>28300</td>\n",
       "      <td>185</td>\n",
       "      <td>UUY8mzqqGwl5_bTpBY9qLMAA</td>\n",
       "      <td>DE</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UC7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>Alex The Analyst</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>My name is Alex Freberg and on this channel I ...</td>\n",
       "      <td>US</td>\n",
       "      <td>8145641</td>\n",
       "      <td>208000</td>\n",
       "      <td>142</td>\n",
       "      <td>UU7cs8q-gJRlGwj4A8OmCmXg</td>\n",
       "      <td>DS_DA</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCAWsBMQY4KSuOuGODki-l7A</td>\n",
       "      <td>Data Interview Pro</td>\n",
       "      <td>2020-09-09</td>\n",
       "      <td>WELCOME! I’M EMMA DING\\n\\nI'm a Data Scientist...</td>\n",
       "      <td>CA</td>\n",
       "      <td>937378</td>\n",
       "      <td>26500</td>\n",
       "      <td>62</td>\n",
       "      <td>UUAWsBMQY4KSuOuGODki-l7A</td>\n",
       "      <td>DS_DA</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCmLGJ3VYBcfRaWbP6JLJcpA</td>\n",
       "      <td>Seattle Data Guy</td>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>Welcome to my channel.\\n\\nI make videos on dat...</td>\n",
       "      <td>US</td>\n",
       "      <td>1284513</td>\n",
       "      <td>28000</td>\n",
       "      <td>128</td>\n",
       "      <td>UUmLGJ3VYBcfRaWbP6JLJcpA</td>\n",
       "      <td>DE</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>Thu Vu data analytics</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>Hi there! Thanks for checking out my channel. ...</td>\n",
       "      <td>US</td>\n",
       "      <td>496223</td>\n",
       "      <td>25300</td>\n",
       "      <td>34</td>\n",
       "      <td>UUJQJAI7IjbLcpsjWdSzYz0Q</td>\n",
       "      <td>DS_DA</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UCAxnMry1lETl47xQWABvH7g</td>\n",
       "      <td>Karolina Sowinska</td>\n",
       "      <td>2013-09-07</td>\n",
       "      <td>If you're curious about data engineering, mach...</td>\n",
       "      <td>GB</td>\n",
       "      <td>1191908</td>\n",
       "      <td>38300</td>\n",
       "      <td>59</td>\n",
       "      <td>UUAxnMry1lETl47xQWABvH7g</td>\n",
       "      <td>DE</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UCAq9f7jFEA7Mtl3qOZy2h1A</td>\n",
       "      <td>Data with Zach</td>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>Hey I'm Zach Wilson! \\n\\nI currently work at A...</td>\n",
       "      <td>US</td>\n",
       "      <td>43497</td>\n",
       "      <td>6070</td>\n",
       "      <td>8</td>\n",
       "      <td>UUAq9f7jFEA7Mtl3qOZy2h1A</td>\n",
       "      <td>DE</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UC2UXDak6o7rBm23k3Vv5dww</td>\n",
       "      <td>Tina Huang</td>\n",
       "      <td>2013-08-28</td>\n",
       "      <td>Hi! My name is Tina and I'm a data scientist a...</td>\n",
       "      <td>US</td>\n",
       "      <td>11367693</td>\n",
       "      <td>306000</td>\n",
       "      <td>96</td>\n",
       "      <td>UU2UXDak6o7rBm23k3Vv5dww</td>\n",
       "      <td>DS_DA</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UCLLw7jmFsvfIVaUFsLs8mlQ</td>\n",
       "      <td>Luke Barousse</td>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>What's up, Data Nerds! I'm Luke, a data analys...</td>\n",
       "      <td>US</td>\n",
       "      <td>7999203</td>\n",
       "      <td>162000</td>\n",
       "      <td>74</td>\n",
       "      <td>UULLw7jmFsvfIVaUFsLs8mlQ</td>\n",
       "      <td>DS_DA</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UCBGcs9XTL5U34oaSn_AsHqw</td>\n",
       "      <td>E-Learning Bridge</td>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>Shashank Mishra : Data Engineer - ||| , Ex-Ama...</td>\n",
       "      <td>IN</td>\n",
       "      <td>2708335</td>\n",
       "      <td>60800</td>\n",
       "      <td>189</td>\n",
       "      <td>UUBGcs9XTL5U34oaSn_AsHqw</td>\n",
       "      <td>DE</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 channel_id          channel_title channel_publish_at  \\\n",
       "0  UCY8mzqqGwl5_bTpBY9qLMAA          Andreas Kretz         2017-04-18   \n",
       "1  UC7cs8q-gJRlGwj4A8OmCmXg       Alex The Analyst         2020-01-08   \n",
       "2  UCAWsBMQY4KSuOuGODki-l7A     Data Interview Pro         2020-09-09   \n",
       "3  UCmLGJ3VYBcfRaWbP6JLJcpA       Seattle Data Guy         2017-01-27   \n",
       "4  UCJQJAI7IjbLcpsjWdSzYz0Q  Thu Vu data analytics         2021-04-30   \n",
       "5  UCAxnMry1lETl47xQWABvH7g      Karolina Sowinska         2013-09-07   \n",
       "6  UCAq9f7jFEA7Mtl3qOZy2h1A         Data with Zach         2013-01-25   \n",
       "7  UC2UXDak6o7rBm23k3Vv5dww             Tina Huang         2013-08-28   \n",
       "8  UCLLw7jmFsvfIVaUFsLs8mlQ          Luke Barousse         2020-08-03   \n",
       "9  UCBGcs9XTL5U34oaSn_AsHqw      E-Learning Bridge         2020-04-23   \n",
       "\n",
       "                                 channel_description channel_country  \\\n",
       "0  I help you get into data engineering, the plum...              DE   \n",
       "1  My name is Alex Freberg and on this channel I ...              US   \n",
       "2  WELCOME! I’M EMMA DING\\n\\nI'm a Data Scientist...              CA   \n",
       "3  Welcome to my channel.\\n\\nI make videos on dat...              US   \n",
       "4  Hi there! Thanks for checking out my channel. ...              US   \n",
       "5  If you're curious about data engineering, mach...              GB   \n",
       "6  Hey I'm Zach Wilson! \\n\\nI currently work at A...              US   \n",
       "7  Hi! My name is Tina and I'm a data scientist a...              US   \n",
       "8  What's up, Data Nerds! I'm Luke, a data analys...              US   \n",
       "9  Shashank Mishra : Data Engineer - ||| , Ex-Ama...              IN   \n",
       "\n",
       "   channel_view_count  channel_subscriber_count  channel_video_count  \\\n",
       "0              746257                     28300                  185   \n",
       "1             8145641                    208000                  142   \n",
       "2              937378                     26500                   62   \n",
       "3             1284513                     28000                  128   \n",
       "4              496223                     25300                   34   \n",
       "5             1191908                     38300                   59   \n",
       "6               43497                      6070                    8   \n",
       "7            11367693                    306000                   96   \n",
       "8             7999203                    162000                   74   \n",
       "9             2708335                     60800                  189   \n",
       "\n",
       "        channel_playlist_id channel_category insert_date  \n",
       "0  UUY8mzqqGwl5_bTpBY9qLMAA               DE  2022-05-03  \n",
       "1  UU7cs8q-gJRlGwj4A8OmCmXg            DS_DA  2022-05-03  \n",
       "2  UUAWsBMQY4KSuOuGODki-l7A            DS_DA  2022-05-03  \n",
       "3  UUmLGJ3VYBcfRaWbP6JLJcpA               DE  2022-05-03  \n",
       "4  UUJQJAI7IjbLcpsjWdSzYz0Q            DS_DA  2022-05-03  \n",
       "5  UUAxnMry1lETl47xQWABvH7g               DE  2022-05-03  \n",
       "6  UUAq9f7jFEA7Mtl3qOZy2h1A               DE  2022-05-03  \n",
       "7  UU2UXDak6o7rBm23k3Vv5dww            DS_DA  2022-05-03  \n",
       "8  UULLw7jmFsvfIVaUFsLs8mlQ            DS_DA  2022-05-03  \n",
       "9  UUBGcs9XTL5U34oaSn_AsHqw               DE  2022-05-03  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel = channel_data_processing(get_channel_info(youtube))\n",
    "channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>definition</th>\n",
       "      <th>caption</th>\n",
       "      <th>tags_count</th>\n",
       "      <th>publishDay</th>\n",
       "      <th>durationinSecs</th>\n",
       "      <th>insert_date</th>\n",
       "      <th>title_2</th>\n",
       "      <th>title_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oJDlPIVJZbw</td>\n",
       "      <td>2022-04-30 14:00:19+00:00</td>\n",
       "      <td>stop being lazy.</td>\n",
       "      <td>Start building your ideal daily routine! The f...</td>\n",
       "      <td>None</td>\n",
       "      <td>24371</td>\n",
       "      <td>1855</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat</td>\n",
       "      <td>723.0</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>stop being lazy</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0QFh1expGNs</td>\n",
       "      <td>2022-04-22 14:30:00+00:00</td>\n",
       "      <td>Career advice for your 20s and 30s</td>\n",
       "      <td>Sign up or learn more about SharpestMinds here...</td>\n",
       "      <td>None</td>\n",
       "      <td>53508</td>\n",
       "      <td>3027</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>Fri</td>\n",
       "      <td>729.0</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>Career advice for your 20s and 30s</td>\n",
       "      <td>[career, advice, 20, 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dw_ko_L232M</td>\n",
       "      <td>2022-04-15 14:30:01+00:00</td>\n",
       "      <td>Books that will pay off HUGE dividends in your...</td>\n",
       "      <td>The first 1000 visitors to https://www.shortfo...</td>\n",
       "      <td>None</td>\n",
       "      <td>38254</td>\n",
       "      <td>2565</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>Fri</td>\n",
       "      <td>860.0</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>Books that will pay off HUGE dividends in your...</td>\n",
       "      <td>[book, pay, huge, dividend, 20, 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_xf1TMs0ysk</td>\n",
       "      <td>2022-04-09 17:30:06+00:00</td>\n",
       "      <td>5 Unique Python Projects (beginner to intermed...</td>\n",
       "      <td>The projects cover a variety of different topi...</td>\n",
       "      <td>None</td>\n",
       "      <td>47993</td>\n",
       "      <td>2786</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>5 Unique Python Projects beginner to intermediate</td>\n",
       "      <td>[python, project]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uQmjcGGCPGA</td>\n",
       "      <td>2022-04-05 16:00:25+00:00</td>\n",
       "      <td>How to save a half-wasted day🥲</td>\n",
       "      <td>Head to http://brilliant.org/TinaHuang/ to get...</td>\n",
       "      <td>None</td>\n",
       "      <td>38875</td>\n",
       "      <td>2750</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>How to save a halfwasted day</td>\n",
       "      <td>[save, halfwasted, day]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>VrJYOItZYLQ</td>\n",
       "      <td>2018-06-04 03:11:15+00:00</td>\n",
       "      <td>Introduction To Time Series In R: The Decompos...</td>\n",
       "      <td>When developing time series models it can be h...</td>\n",
       "      <td>[data science, r programming, programming, ana...</td>\n",
       "      <td>13559</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon</td>\n",
       "      <td>453.0</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>Introduction To Time Series In R The Decompose...</td>\n",
       "      <td>[introduction, series, r, decompose, function]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>1NCVy8Tylx0</td>\n",
       "      <td>2018-05-29 05:15:48+00:00</td>\n",
       "      <td>What Are Confounding Variables and How Do You ...</td>\n",
       "      <td>A variable that is not considered but plays a ...</td>\n",
       "      <td>[math, epidemiology, statistics, analytics, al...</td>\n",
       "      <td>1558</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>9</td>\n",
       "      <td>Tue</td>\n",
       "      <td>674.0</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>What Are Confounding Variables and How Do You ...</td>\n",
       "      <td>[confound, variable, standardize, population]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>KgHtG0OI1fg</td>\n",
       "      <td>2018-05-28 23:07:01+00:00</td>\n",
       "      <td>Introduction To Time Series In R: Measuring Pr...</td>\n",
       "      <td>When developing predictive models and algorith...</td>\n",
       "      <td>[Data science, R programming, Introduction, Le...</td>\n",
       "      <td>6824</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>8</td>\n",
       "      <td>Mon</td>\n",
       "      <td>697.0</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>Introduction To Time Series In R Measuring Pre...</td>\n",
       "      <td>[introduction, series, r, predictive, model, q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>8cKeAH2aGVI</td>\n",
       "      <td>2018-05-24 14:34:40+00:00</td>\n",
       "      <td>Introduction To Time Series In R Basic Models</td>\n",
       "      <td>In this video we will be discussing some of th...</td>\n",
       "      <td>[data science, r programming, Modeling, foreca...</td>\n",
       "      <td>9305</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>8</td>\n",
       "      <td>Thu</td>\n",
       "      <td>631.0</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>Introduction To Time Series In R Basic Models</td>\n",
       "      <td>[introduction, series, r, basic, model]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>uW3PQmzvUcw</td>\n",
       "      <td>2018-05-24 14:08:41+00:00</td>\n",
       "      <td>Introduction To Time Series In R</td>\n",
       "      <td>What is a time series in R and how do you crea...</td>\n",
       "      <td>[Statistics, R Programming, Data science, Mode...</td>\n",
       "      <td>51979</td>\n",
       "      <td>388</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>hd</td>\n",
       "      <td>false</td>\n",
       "      <td>5</td>\n",
       "      <td>Thu</td>\n",
       "      <td>476.0</td>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>Introduction To Time Series In R</td>\n",
       "      <td>[introduction, series, r]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>977 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id               publishedAt  \\\n",
       "0    oJDlPIVJZbw 2022-04-30 14:00:19+00:00   \n",
       "1    0QFh1expGNs 2022-04-22 14:30:00+00:00   \n",
       "2    Dw_ko_L232M 2022-04-15 14:30:01+00:00   \n",
       "3    _xf1TMs0ysk 2022-04-09 17:30:06+00:00   \n",
       "4    uQmjcGGCPGA 2022-04-05 16:00:25+00:00   \n",
       "..           ...                       ...   \n",
       "972  VrJYOItZYLQ 2018-06-04 03:11:15+00:00   \n",
       "973  1NCVy8Tylx0 2018-05-29 05:15:48+00:00   \n",
       "974  KgHtG0OI1fg 2018-05-28 23:07:01+00:00   \n",
       "975  8cKeAH2aGVI 2018-05-24 14:34:40+00:00   \n",
       "976  uW3PQmzvUcw 2018-05-24 14:08:41+00:00   \n",
       "\n",
       "                                                 title  \\\n",
       "0                                     stop being lazy.   \n",
       "1                   Career advice for your 20s and 30s   \n",
       "2    Books that will pay off HUGE dividends in your...   \n",
       "3    5 Unique Python Projects (beginner to intermed...   \n",
       "4                       How to save a half-wasted day🥲   \n",
       "..                                                 ...   \n",
       "972  Introduction To Time Series In R: The Decompos...   \n",
       "973  What Are Confounding Variables and How Do You ...   \n",
       "974  Introduction To Time Series In R: Measuring Pr...   \n",
       "975      Introduction To Time Series In R Basic Models   \n",
       "976                   Introduction To Time Series In R   \n",
       "\n",
       "                                           description  \\\n",
       "0    Start building your ideal daily routine! The f...   \n",
       "1    Sign up or learn more about SharpestMinds here...   \n",
       "2    The first 1000 visitors to https://www.shortfo...   \n",
       "3    The projects cover a variety of different topi...   \n",
       "4    Head to http://brilliant.org/TinaHuang/ to get...   \n",
       "..                                                 ...   \n",
       "972  When developing time series models it can be h...   \n",
       "973  A variable that is not considered but plays a ...   \n",
       "974  When developing predictive models and algorith...   \n",
       "975  In this video we will be discussing some of th...   \n",
       "976  What is a time series in R and how do you crea...   \n",
       "\n",
       "                                                  tags  viewCount  likeCount  \\\n",
       "0                                                 None      24371       1855   \n",
       "1                                                 None      53508       3027   \n",
       "2                                                 None      38254       2565   \n",
       "3                                                 None      47993       2786   \n",
       "4                                                 None      38875       2750   \n",
       "..                                                 ...        ...        ...   \n",
       "972  [data science, r programming, programming, ana...      13559        144   \n",
       "973  [math, epidemiology, statistics, analytics, al...       1558         13   \n",
       "974  [Data science, R programming, Introduction, Le...       6824         57   \n",
       "975  [data science, r programming, Modeling, foreca...       9305        107   \n",
       "976  [Statistics, R Programming, Data science, Mode...      51979        388   \n",
       "\n",
       "     favoriteCount  commentCount definition caption  tags_count publishDay  \\\n",
       "0                0           117         hd   false           0        Sat   \n",
       "1                0           252         hd   false           0        Fri   \n",
       "2                0           164         hd   false           0        Fri   \n",
       "3                0            98         hd   false           0        Sat   \n",
       "4                0           176         hd   false           0        Tue   \n",
       "..             ...           ...        ...     ...         ...        ...   \n",
       "972              0             2         hd   false           7        Mon   \n",
       "973              0             4         hd   false           9        Tue   \n",
       "974              0             4         hd   false           8        Mon   \n",
       "975              0             3         hd   false           8        Thu   \n",
       "976              0            20         hd   false           5        Thu   \n",
       "\n",
       "     durationinSecs insert_date  \\\n",
       "0             723.0  2022-05-03   \n",
       "1             729.0  2022-05-03   \n",
       "2             860.0  2022-05-03   \n",
       "3            1014.0  2022-05-03   \n",
       "4             520.0  2022-05-03   \n",
       "..              ...         ...   \n",
       "972           453.0  2022-05-03   \n",
       "973           674.0  2022-05-03   \n",
       "974           697.0  2022-05-03   \n",
       "975           631.0  2022-05-03   \n",
       "976           476.0  2022-05-03   \n",
       "\n",
       "                                               title_2  \\\n",
       "0                                      stop being lazy   \n",
       "1                   Career advice for your 20s and 30s   \n",
       "2    Books that will pay off HUGE dividends in your...   \n",
       "3    5 Unique Python Projects beginner to intermediate   \n",
       "4                         How to save a halfwasted day   \n",
       "..                                                 ...   \n",
       "972  Introduction To Time Series In R The Decompose...   \n",
       "973  What Are Confounding Variables and How Do You ...   \n",
       "974  Introduction To Time Series In R Measuring Pre...   \n",
       "975      Introduction To Time Series In R Basic Models   \n",
       "976                   Introduction To Time Series In R   \n",
       "\n",
       "                                            title_word  \n",
       "0                                                   []  \n",
       "1                             [career, advice, 20, 30]  \n",
       "2                  [book, pay, huge, dividend, 20, 30]  \n",
       "3                                    [python, project]  \n",
       "4                              [save, halfwasted, day]  \n",
       "..                                                 ...  \n",
       "972     [introduction, series, r, decompose, function]  \n",
       "973      [confound, variable, standardize, population]  \n",
       "974  [introduction, series, r, predictive, model, q...  \n",
       "975            [introduction, series, r, basic, model]  \n",
       "976                          [introduction, series, r]  \n",
       "\n",
       "[977 rows x 17 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = video_data_processing(get_video_info(youtube))\n",
    "video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_id</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>channel_category</th>\n",
       "      <th>video_id</th>\n",
       "      <th>title_word</th>\n",
       "      <th>insert_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UC2UXDak6o7rBm23k3Vv5dww</td>\n",
       "      <td>Tina Huang</td>\n",
       "      <td>DS_DA</td>\n",
       "      <td>oJDlPIVJZbw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UC2UXDak6o7rBm23k3Vv5dww</td>\n",
       "      <td>Tina Huang</td>\n",
       "      <td>DS_DA</td>\n",
       "      <td>0QFh1expGNs</td>\n",
       "      <td>career</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UC2UXDak6o7rBm23k3Vv5dww</td>\n",
       "      <td>Tina Huang</td>\n",
       "      <td>DS_DA</td>\n",
       "      <td>0QFh1expGNs</td>\n",
       "      <td>advice</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UC2UXDak6o7rBm23k3Vv5dww</td>\n",
       "      <td>Tina Huang</td>\n",
       "      <td>DS_DA</td>\n",
       "      <td>0QFh1expGNs</td>\n",
       "      <td>20</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UC2UXDak6o7rBm23k3Vv5dww</td>\n",
       "      <td>Tina Huang</td>\n",
       "      <td>DS_DA</td>\n",
       "      <td>0QFh1expGNs</td>\n",
       "      <td>30</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>UCmLGJ3VYBcfRaWbP6JLJcpA</td>\n",
       "      <td>Seattle Data Guy</td>\n",
       "      <td>DE</td>\n",
       "      <td>8cKeAH2aGVI</td>\n",
       "      <td>basic</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4862</th>\n",
       "      <td>UCmLGJ3VYBcfRaWbP6JLJcpA</td>\n",
       "      <td>Seattle Data Guy</td>\n",
       "      <td>DE</td>\n",
       "      <td>8cKeAH2aGVI</td>\n",
       "      <td>model</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4863</th>\n",
       "      <td>UCmLGJ3VYBcfRaWbP6JLJcpA</td>\n",
       "      <td>Seattle Data Guy</td>\n",
       "      <td>DE</td>\n",
       "      <td>uW3PQmzvUcw</td>\n",
       "      <td>introduction</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4864</th>\n",
       "      <td>UCmLGJ3VYBcfRaWbP6JLJcpA</td>\n",
       "      <td>Seattle Data Guy</td>\n",
       "      <td>DE</td>\n",
       "      <td>uW3PQmzvUcw</td>\n",
       "      <td>series</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4865</th>\n",
       "      <td>UCmLGJ3VYBcfRaWbP6JLJcpA</td>\n",
       "      <td>Seattle Data Guy</td>\n",
       "      <td>DE</td>\n",
       "      <td>uW3PQmzvUcw</td>\n",
       "      <td>r</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4866 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    channel_id     channel_title channel_category  \\\n",
       "0     UC2UXDak6o7rBm23k3Vv5dww        Tina Huang            DS_DA   \n",
       "1     UC2UXDak6o7rBm23k3Vv5dww        Tina Huang            DS_DA   \n",
       "2     UC2UXDak6o7rBm23k3Vv5dww        Tina Huang            DS_DA   \n",
       "3     UC2UXDak6o7rBm23k3Vv5dww        Tina Huang            DS_DA   \n",
       "4     UC2UXDak6o7rBm23k3Vv5dww        Tina Huang            DS_DA   \n",
       "...                        ...               ...              ...   \n",
       "4861  UCmLGJ3VYBcfRaWbP6JLJcpA  Seattle Data Guy               DE   \n",
       "4862  UCmLGJ3VYBcfRaWbP6JLJcpA  Seattle Data Guy               DE   \n",
       "4863  UCmLGJ3VYBcfRaWbP6JLJcpA  Seattle Data Guy               DE   \n",
       "4864  UCmLGJ3VYBcfRaWbP6JLJcpA  Seattle Data Guy               DE   \n",
       "4865  UCmLGJ3VYBcfRaWbP6JLJcpA  Seattle Data Guy               DE   \n",
       "\n",
       "         video_id    title_word   insert_at  \n",
       "0     oJDlPIVJZbw           NaN  2022-05-03  \n",
       "1     0QFh1expGNs        career  2022-05-03  \n",
       "2     0QFh1expGNs        advice  2022-05-03  \n",
       "3     0QFh1expGNs            20  2022-05-03  \n",
       "4     0QFh1expGNs            30  2022-05-03  \n",
       "...           ...           ...         ...  \n",
       "4861  8cKeAH2aGVI         basic  2022-05-03  \n",
       "4862  8cKeAH2aGVI         model  2022-05-03  \n",
       "4863  uW3PQmzvUcw  introduction  2022-05-03  \n",
       "4864  uW3PQmzvUcw        series  2022-05-03  \n",
       "4865  uW3PQmzvUcw             r  2022-05-03  \n",
       "\n",
       "[4866 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_key_words = video[['video_id','title_word']].explode('title_word').drop_duplicates()\n",
    "title_key_words = title_key_words.merge(playlist, how = 'inner', on = ['video_id'])\n",
    "title_key_words = title_key_words.merge(channel, how = 'inner',left_on= ['playlist_id'], right_on = ['channel_playlist_id'])\n",
    "title_key_words = title_key_words[[\"channel_id\",\"channel_title\",\"channel_category\",\"video_id\",\"title_word\"]]\n",
    "title_key_words['insert_at'] = pd.to_datetime('today').date()\n",
    "title_key_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id      4866\n",
       "title_word    4866\n",
       "insert_at     4866\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_key_words = video[['video_id','title_word']].explode('title_word').fillna('no info').drop_duplicates()\n",
    "video_key_words['insert_at'] = pd.to_datetime('today').date()\n",
    "video_key_words = video_key_words.reset_index(drop=True)\n",
    "video_key_words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineer</th>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interview</th>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analyst</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sql</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scientist</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>project</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tutorial</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>software</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analytics</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faang</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tableau</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysis</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explain</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spark</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cod</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resume</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>certificate</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>college</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apache</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistake</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aws</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lpa</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>portfolio</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazon</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internship</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>startup</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roadmap</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             total\n",
       "title_word        \n",
       "data           536\n",
       "engineer       236\n",
       "science        161\n",
       "interview      133\n",
       "analyst        129\n",
       "job             90\n",
       "sql             66\n",
       "scientist       63\n",
       "python          49\n",
       "project         47\n",
       "tutorial        42\n",
       "skill           37\n",
       "experience      36\n",
       "question        34\n",
       "google          27\n",
       "software        27\n",
       "company         26\n",
       "analytics       26\n",
       "salary          25\n",
       "career          24\n",
       "machine         23\n",
       "study           23\n",
       "faang           22\n",
       "review          21\n",
       "tableau         20\n",
       "day             20\n",
       "analysis        20\n",
       "explain         19\n",
       "spark           18\n",
       "cod             18\n",
       "case            18\n",
       "resume          17\n",
       "life            17\n",
       "certificate     17\n",
       "college         17\n",
       "apache          16\n",
       "mistake         16\n",
       "aws             16\n",
       "lpa             16\n",
       "portfolio       16\n",
       "tech            15\n",
       "offer           15\n",
       "amazon          15\n",
       "test            15\n",
       "internship      14\n",
       "startup         14\n",
       "process         14\n",
       "roadmap         14\n",
       "student         13\n",
       "product         13"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_key_words.groupby(['title_word']).agg(total = ('title_word','count')).sort_values(['total'], ascending = False)[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>insert_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oJDlPIVJZbw</td>\n",
       "      <td>No Info</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0QFh1expGNs</td>\n",
       "      <td>No Info</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dw_ko_L232M</td>\n",
       "      <td>No Info</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_xf1TMs0ysk</td>\n",
       "      <td>No Info</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uQmjcGGCPGA</td>\n",
       "      <td>No Info</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15546</th>\n",
       "      <td>uW3PQmzvUcw</td>\n",
       "      <td>Statistics</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15547</th>\n",
       "      <td>uW3PQmzvUcw</td>\n",
       "      <td>R Programming</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15548</th>\n",
       "      <td>uW3PQmzvUcw</td>\n",
       "      <td>Data science</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15549</th>\n",
       "      <td>uW3PQmzvUcw</td>\n",
       "      <td>Modeling</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15550</th>\n",
       "      <td>uW3PQmzvUcw</td>\n",
       "      <td>Predictive Forecasting</td>\n",
       "      <td>2022-05-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15551 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id                    tags   insert_at\n",
       "0      oJDlPIVJZbw                 No Info  2022-05-03\n",
       "1      0QFh1expGNs                 No Info  2022-05-03\n",
       "2      Dw_ko_L232M                 No Info  2022-05-03\n",
       "3      _xf1TMs0ysk                 No Info  2022-05-03\n",
       "4      uQmjcGGCPGA                 No Info  2022-05-03\n",
       "...            ...                     ...         ...\n",
       "15546  uW3PQmzvUcw              Statistics  2022-05-03\n",
       "15547  uW3PQmzvUcw           R Programming  2022-05-03\n",
       "15548  uW3PQmzvUcw            Data science  2022-05-03\n",
       "15549  uW3PQmzvUcw                Modeling  2022-05-03\n",
       "15550  uW3PQmzvUcw  Predictive Forecasting  2022-05-03\n",
       "\n",
       "[15551 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = video[['video_id','tags']].explode('tags').fillna('No Info')\n",
    "tags['insert_at'] = pd.to_datetime('today').date()\n",
    "tags = tags.reset_index(drop=True)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(video['tags_count']) == tags[tags['tags']!='No Info']['tags'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 977 entries, 0 to 976\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype                  \n",
      "---  ------          --------------  -----                  \n",
      " 0   video_id        977 non-null    object                 \n",
      " 1   publishedAt     977 non-null    datetime64[ns, tzutc()]\n",
      " 2   title           977 non-null    object                 \n",
      " 3   description     977 non-null    object                 \n",
      " 4   viewCount       977 non-null    int64                  \n",
      " 5   likeCount       977 non-null    int64                  \n",
      " 6   favoriteCount   977 non-null    int64                  \n",
      " 7   commentCount    977 non-null    int64                  \n",
      " 8   definition      977 non-null    object                 \n",
      " 9   caption         977 non-null    object                 \n",
      " 10  tags_count      977 non-null    int64                  \n",
      " 11  publishDay      977 non-null    object                 \n",
      " 12  durationinSecs  977 non-null    float64                \n",
      " 13  insert_date     977 non-null    object                 \n",
      "dtypes: datetime64[ns, tzutc()](1), float64(1), int64(5), object(7)\n",
      "memory usage: 107.0+ KB\n"
     ]
    }
   ],
   "source": [
    "video = video.drop(['tags','title_word','title_2'], axis = 1)\n",
    "video.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id     object\n",
       "tags         object\n",
       "insert_at    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playlist_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UU2UXDak6o7rBm23k3Vv5dww</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UU7cs8q-gJRlGwj4A8OmCmXg</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UUAWsBMQY4KSuOuGODki-l7A</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UUAq9f7jFEA7Mtl3qOZy2h1A</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UUAxnMry1lETl47xQWABvH7g</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UUBGcs9XTL5U34oaSn_AsHqw</th>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UUJQJAI7IjbLcpsjWdSzYz0Q</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UULLw7jmFsvfIVaUFsLs8mlQ</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UUY8mzqqGwl5_bTpBY9qLMAA</th>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UUmLGJ3VYBcfRaWbP6JLJcpA</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          total\n",
       "playlist_id                    \n",
       "UU2UXDak6o7rBm23k3Vv5dww     96\n",
       "UU7cs8q-gJRlGwj4A8OmCmXg    142\n",
       "UUAWsBMQY4KSuOuGODki-l7A     62\n",
       "UUAq9f7jFEA7Mtl3qOZy2h1A      8\n",
       "UUAxnMry1lETl47xQWABvH7g     59\n",
       "UUBGcs9XTL5U34oaSn_AsHqw    189\n",
       "UUJQJAI7IjbLcpsjWdSzYz0Q     34\n",
       "UULLw7jmFsvfIVaUFsLs8mlQ     74\n",
       "UUY8mzqqGwl5_bTpBY9qLMAA    185\n",
       "UUmLGJ3VYBcfRaWbP6JLJcpA    128"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist.groupby(['playlist_id']).agg(total = ('video_id','count'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id          False\n",
       "publishedAt       False\n",
       "title             False\n",
       "description       False\n",
       "viewCount         False\n",
       "likeCount         False\n",
       "favoriteCount     False\n",
       "commentCount      False\n",
       "definition        False\n",
       "caption           False\n",
       "tags_count        False\n",
       "publishDay        False\n",
       "durationinSecs    False\n",
       "insert_date       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id                           object\n",
       "publishedAt       datetime64[ns, tzutc()]\n",
       "title                              object\n",
       "description                        object\n",
       "viewCount                           int64\n",
       "likeCount                           int64\n",
       "favoriteCount                       int64\n",
       "commentCount                        int64\n",
       "definition                         object\n",
       "caption                            object\n",
       "tags_count                          int64\n",
       "publishDay                         object\n",
       "durationinSecs                    float64\n",
       "insert_date                        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'youtubedb.c0rhkwuqbdtc.us-west-2.rds.amazonaws.com'\n",
    "port = 3306\n",
    "user = 'admin'\n",
    "password = 'Coco0326happy!12'\n",
    "database = 'youtube'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from pymysql.constants import CLIENT\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pymysql.connect(host = host, user = user, password=password, port = port, database= database, client_flag =  CLIENT.MULTI_STATEMENTS, autocommit = True )\n",
    "cursor = db.cursor()\n",
    "cursor\n",
    "cursor.execute(\"select version()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('information_schema',),\n",
       " ('mysql',),\n",
       " ('performance_schema',),\n",
       " ('sys',),\n",
       " ('test',),\n",
       " ('youtube',),\n",
       " ('youtube_analysis',))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"show databases\")\n",
    "# for database in cursor:\n",
    "#     print(database)\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cursor.execute(\"USE {}\".format(database))\n",
    "except pymysql.Error as err:\n",
    "    print(\"Database {} does not exists.\".format(database))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "\n",
    "  cursor.execute('''\n",
    "    DROP TABLE IF EXISTS channel;\n",
    "    DROP TABLE IF EXISTS playlist;\n",
    "    DROP TABLE IF EXISTS video;\n",
    "    DROP TABLE IF EXISTS tag;\n",
    "    DROP TABLE IF EXISTS video_key_word;\n",
    "    DROP TABLE IF EXISTS clean_video_key_word;\n",
    "    # DROP TABLE IF EXISTS tmp_playlist;\n",
    "    # DROP TABLE IF EXISTS tmp_video;\n",
    "    # DROP TABLE IF EXISTS tmp_channel;\n",
    "\n",
    "  '''\n",
    "\n",
    ")\n",
    "except pymysql.Error as err:\n",
    "  print(err)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "  cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS channel(\n",
    "      channel_id  varchar(255) PRIMARY KEY,\n",
    "      channel_title text NOT NULL,\n",
    "      channel_publish_at text,\n",
    "      channel_description text,\n",
    "      channel_country varchar(3),\n",
    "      channel_view_count INT,\n",
    "      channel_subscriber_count INT,\n",
    "      channel_video_count INT,\n",
    "      channel_playlist_id text,\n",
    "      channel_category text,\n",
    "      insert_date date\n",
    "      );\n",
    "\n",
    "  ''')\n",
    "except pymysql.Error as err:\n",
    "  print(err)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "  cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS playlist(\n",
    "      playlist_id varchar(255) not null,\n",
    "      video_id varchar(255) not null,\n",
    "      primary key (playlist_id, video_id),\n",
    "      insert_date date\n",
    "      );\n",
    "\n",
    "  ''')\n",
    "except pymysql.Error as err:\n",
    "  print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "  cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS video(\n",
    "      video_id varchar(255) primary key,\n",
    "      publishedAt datetime,\n",
    "      title text,\n",
    "      description text,\n",
    "      viewCount int,\n",
    "      likeCount int,\n",
    "      favoriteCount int, \n",
    "      commentCount int,\n",
    "      definition text,\n",
    "      caption text,\n",
    "      tags_count int,\n",
    "      publishDay varchar(3),\n",
    "      durationinSecs float,\n",
    "      insert_date date\n",
    "      );\n",
    "\n",
    "  ''')\n",
    "except pymysql.Error as err:\n",
    "  print(err)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "  cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS video_key_word(\n",
    "      video_id varchar(255),\n",
    "      title_word varchar(255),\n",
    "      insert_at date,\n",
    "      primary key (video_id, title_word)\n",
    "      );\n",
    "\n",
    "  ''')\n",
    "except pymysql.Error as err:\n",
    "  print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "  cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS tag(\n",
    "      video_id varchar(255),\n",
    "      tags varchar(255),\n",
    "      insert_at date,\n",
    "      primary key (video_id, tags)\n",
    "      );\n",
    "\n",
    "  ''')\n",
    "except pymysql.Error as err:\n",
    "  print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel_id          object\n",
       "channel_title       object\n",
       "channel_category    object\n",
       "video_id            object\n",
       "title_word          object\n",
       "insert_at           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_key_words.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "  cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS clean_video_key_word(\n",
    "      channel_id  varchar(255),\n",
    "      channel_title  varchar(255),\n",
    "      channel_category varchar(255),\n",
    "      video_id varchar(255),\n",
    "      title_word varchar(255),\n",
    "      insert_at date,\n",
    "      primary key (channel_id, video_id,title_word)\n",
    "      );\n",
    "\n",
    "  ''')\n",
    "except pymysql.Error as err:\n",
    "  print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('channel',),\n",
       " ('clean_video_key_word',),\n",
       " ('playlist',),\n",
       " ('tag',),\n",
       " ('video',),\n",
       " ('video_key_word',))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"show tables\")\n",
    "cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+pymysql://{user}:{password}@{host}:3306/{database}'.format(user = user, password = password, host = host, database = database))\n",
    "\n",
    "engine.connect().execute(\n",
    "    \"\"\"\n",
    "\n",
    "    CREATE TEMPORARY TABLE IF NOT EXISTS tmp_channel AS SELECT * FROM channel LIMIT 0;\n",
    "    \"\"\")\n",
    "channel.to_sql(\"tmp_channel\", con = engine, if_exists='append', index = False)\n",
    "    #Moving data from temp table to production table\n",
    "engine.connect().execute(\n",
    "    \"\"\"\n",
    "    INSERT INTO channel \n",
    "    SELECT *\n",
    "    FROM tmp_channel\n",
    "    ON DUPLICATE KEY \n",
    "    update channel_description = tmp_channel.channel_description,\n",
    "    channel_country = tmp_channel.channel_country,\n",
    "    channel_view_count = tmp_channel.channel_view_count,\n",
    "    channel_subscriber_count = tmp_channel.channel_subscriber_count,\n",
    "    channel_video_count = tmp_channel.channel_video_count,\n",
    "    channel_playlist_id = tmp_channel.channel_playlist_id,\n",
    "    channel_category = tmp_channel.channel_category,\n",
    "    insert_date  = tmp_channel.insert_date;\n",
    "    \n",
    "    \"\"\")\n",
    "\n",
    "cursor.execute(\n",
    "    \"\"\"\n",
    "   DROP TABLE tmp_channel;   \n",
    "    \"\"\")\n",
    "\n",
    "db.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.connect().execute(\n",
    "    \"\"\"\n",
    "    CREATE TEMPORARY TABLE IF NOT EXISTS tmp_playlist AS SELECT * FROM playlist LIMIT 0;\n",
    "    \"\"\")\n",
    "playlist.to_sql(\"tmp_playlist\", con = engine, if_exists='append', index = False)\n",
    "    #Moving data from temp table to production table\n",
    "engine.connect().execute(\n",
    "    \"\"\"\n",
    "    INSERT INTO playlist \n",
    "    SELECT *\n",
    "    FROM tmp_playlist \n",
    "    ON DUPLICATE KEY \n",
    "    update playlist_id  = tmp_playlist.playlist_id ,\n",
    "    video_id  = tmp_playlist.video_id,\n",
    "    insert_date  = tmp_playlist.insert_date;\n",
    "    \n",
    "    \"\"\")\n",
    "cursor.execute(\"\"\"\n",
    "    drop table tmp_playlist;\"\"\")\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.connect().execute(\n",
    "    \"\"\"\n",
    "    CREATE TEMPORARY TABLE IF NOT EXISTS tmp_video AS SELECT * FROM video LIMIT 0;\n",
    "    \"\"\")\n",
    "db.commit()\n",
    "video.to_sql(\"tmp_video\", con = engine, if_exists='append', index = False)\n",
    "    #Moving data from temp table to production table\n",
    "engine.connect().execute(\n",
    "    \"\"\"\n",
    "    INSERT INTO video \n",
    "    SELECT *\n",
    "    FROM tmp_video \n",
    "    ON DUPLICATE KEY \n",
    "    update description  = tmp_video.description ,\n",
    "     viewCount  = tmp_video.viewCount,\n",
    "     likeCount  = tmp_video.likeCount,\n",
    "     favoriteCount   = tmp_video.favoriteCount ,\n",
    "     commentCount   = tmp_video.commentCount ,\n",
    "     insert_date    = tmp_video.insert_date ;\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"  drop table tmp_video;\n",
    "\"\"\")\n",
    "db.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "engine.connect().execute(\n",
    "    \"\"\"\n",
    "    CREATE TEMPORARY TABLE IF NOT EXISTS tmp_tag AS SELECT * FROM tag LIMIT 0;\n",
    "    \"\"\")\n",
    "tags.to_sql(\"tmp_tag\", con = engine, if_exists='replace', index = False)\n",
    "    #Moving data from temp table to production table\n",
    "engine.connect().execute(\n",
    "    \"\"\"\n",
    "    INSERT INTO tag\n",
    "    SELECT *\n",
    "    FROM tmp_tag\n",
    "    ON DUPLICATE KEY    \n",
    "    update\n",
    "    insert_at   = tmp_tag.insert_at ;\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"  drop table tmp_tag;\n",
    "\"\"\")\n",
    "db.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id      4866\n",
       "title_word    4866\n",
       "insert_at     4866\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_key_words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = video_key_words.drop_duplicates())\n",
    "# test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "engine.connect().execute(\n",
    "    \"\"\"\n",
    "    CREATE TEMPORARY TABLE IF NOT EXISTS tmp_video_key_word AS SELECT * FROM video_key_word LIMIT 0;\n",
    "    \"\"\")\n",
    "video_key_words.to_sql(\"tmp_video_key_word\", con = engine, if_exists='replace', index = False)\n",
    "    #Moving data from temp table to production table\n",
    "engine.connect().execute(\n",
    "    \"\"\"\n",
    "    INSERT INTO video_key_word\n",
    "    SELECT *\n",
    "    FROM tmp_video_key_word\n",
    "    ON DUPLICATE KEY    \n",
    "    update\n",
    "    insert_at   = tmp_video_key_word.insert_at ;\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"  drop table tmp_video_key_word;\n",
    "\"\"\")\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.connect().execute(\n",
    "    \"\"\"\n",
    "    INSERT INTO clean_video_key_word\n",
    "    SELECT channel_id,channel_title, channel_category, video_key_word.video_id, video_key_word.title_word, video_key_word.insert_at\n",
    "    FROM channel join playlist on channel.channel_playlist_id = playlist.playlist_id\n",
    "    join video_key_word on playlist.video_id = video_key_word.video_id\n",
    "    ON DUPLICATE KEY    \n",
    "    update\n",
    "    insert_at  = video_key_word.insert_at ;\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.connect().close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
